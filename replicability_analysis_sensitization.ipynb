{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d281a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from copy import deepcopy\n",
    "from tensorly.metrics import congruence_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89238204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading cp_2_0.0: [Errno 2] No such file or directory: 'Sensitization/results/replicability/factors_cp_2_components_l_B_0.0_splits_10.pkl'\n",
      "Error loading cp_3_0.0: [Errno 2] No such file or directory: 'Sensitization/results/replicability/factors_cp_3_components_l_B_0.0_splits_10.pkl'\n",
      "Error loading cp_4_0.0: [Errno 2] No such file or directory: 'Sensitization/results/replicability/factors_cp_4_components_l_B_0.0_splits_10.pkl'\n",
      "Error loading cp_5_0.0: [Errno 2] No such file or directory: 'Sensitization/results/replicability/factors_cp_5_components_l_B_0.0_splits_10.pkl'\n",
      "Error loading cp_6_0.0: [Errno 2] No such file or directory: 'Sensitization/results/replicability/factors_cp_6_components_l_B_0.0_splits_10.pkl'\n",
      "Error loading parafac2_2_0.0: [Errno 2] No such file or directory: 'Sensitization/results/replicability/factors_parafac2_2_components_l_B_0.0_splits_10.pkl'\n",
      "Error loading parafac2_3_0.0: [Errno 2] No such file or directory: 'Sensitization/results/replicability/factors_parafac2_3_components_l_B_0.0_splits_10.pkl'\n",
      "Error loading parafac2_4_0.0: [Errno 2] No such file or directory: 'Sensitization/results/replicability/factors_parafac2_4_components_l_B_0.0_splits_10.pkl'\n",
      "Error loading parafac2_5_0.0: [Errno 2] No such file or directory: 'Sensitization/results/replicability/factors_parafac2_5_components_l_B_0.0_splits_10.pkl'\n",
      "Error loading parafac2_6_0.0: [Errno 2] No such file or directory: 'Sensitization/results/replicability/factors_parafac2_6_components_l_B_0.0_splits_10.pkl'\n",
      "Error loading cmf_2_0.0: [Errno 2] No such file or directory: 'Sensitization/results/replicability/factors_cmf_2_components_l_B_0.0_splits_10.pkl'\n",
      "Error loading cmf_3_0.0: [Errno 2] No such file or directory: 'Sensitization/results/replicability/factors_cmf_3_components_l_B_0.0_splits_10.pkl'\n",
      "Error loading cmf_4_0.0: [Errno 2] No such file or directory: 'Sensitization/results/replicability/factors_cmf_4_components_l_B_0.0_splits_10.pkl'\n",
      "Error loading cmf_5_0.0: [Errno 2] No such file or directory: 'Sensitization/results/replicability/factors_cmf_5_components_l_B_0.0_splits_10.pkl'\n",
      "Error loading cmf_6_0.0: [Errno 2] No such file or directory: 'Sensitization/results/replicability/factors_cmf_6_components_l_B_0.0_splits_10.pkl'\n"
     ]
    }
   ],
   "source": [
    "fmss_A = {}\n",
    "fmss_CB = {}\n",
    "\n",
    "repeats = 10\n",
    "\n",
    "for model in ['cp','parafac2','cmf']:\n",
    "    for no_of_components in [2,3,4,5,6]:\n",
    "        for l_B in [0.0]:\n",
    "            for splits in [10]:\n",
    "                try:\n",
    "\n",
    "                    with open(f\"Sensitization/results/replicability/factors_{model}_{no_of_components}_components_l_B_{l_B}_splits_{splits}.pkl\", \"rb\") as f:\n",
    "                        args = pickle.load(f)\n",
    "\n",
    "                    fmss_A[f'{model}_{no_of_components}_{l_B}_{splits}'] = []\n",
    "                    fmss_CB[f'{model}_{no_of_components}_{l_B}_{splits}'] = []\n",
    "\n",
    "                    seen_pairs = set()\n",
    "                    for r in range(repeats):\n",
    "                        for s in range(splits):\n",
    "\n",
    "                            # Get the target factors2compare once for this (r, s)\n",
    "                            thing2compare = next((arg[\"factors\"],arg[\"sorted_train_index\"]) for arg in args if arg[\"r\"] == r and arg[\"s\"] == s)\n",
    "                            factors2compare = thing2compare[0]\n",
    "                            sorted_train_index2compare = thing2compare[1]\n",
    "\n",
    "                            idx_ref = (r, s)\n",
    "\n",
    "                            for arg in args:\n",
    "                                idx_cmp = (arg[\"r\"], arg[\"s\"])\n",
    "                                if arg[\"r\"] == r and arg[\"s\"] != s:\n",
    "                                    # Sort to form an unordered pair key to avoid double counting\n",
    "                                    pair_key = tuple(sorted([idx_ref, idx_cmp]))\n",
    "\n",
    "                                    if pair_key not in seen_pairs:\n",
    "\n",
    "                                        factors2comparewith = arg[\"factors\"]\n",
    "                                        sorted_train_index2comparewith = arg[\"sorted_train_index\"]\n",
    "\n",
    "                                        if factors2comparewith is None or factors2compare is None:\n",
    "                                            continue\n",
    "\n",
    "                                        # Find common indices\n",
    "                                        common_indices = sorted(set(sorted_train_index2compare).intersection(set(sorted_train_index2comparewith)))\n",
    "\n",
    "                                        subjects2use1 = []\n",
    "                                        subjects2use2 = []\n",
    "\n",
    "                                        for common_idx in common_indices:\n",
    "                                            subjects2use1.append(sorted_train_index2compare.index(common_idx))\n",
    "                                            subjects2use2.append(sorted_train_index2comparewith.index(common_idx))\n",
    "\n",
    "                                        if common_indices == []:\n",
    "                                            print(\"No common subjects found!\")\n",
    "\n",
    "                                        if model != 'cp':\n",
    "\n",
    "                                            A1 = deepcopy(factors2compare[2])\n",
    "                                            A2 = deepcopy(factors2comparewith[2])\n",
    "\n",
    "                                            B1 = [deepcopy(factors2compare[1][i]) for i in subjects2use1]\n",
    "                                            B2 = [deepcopy(factors2comparewith[1][i]) for i in subjects2use2]\n",
    "\n",
    "                                            C1 = deepcopy(factors2compare[0][subjects2use1,:])\n",
    "                                            C2 = deepcopy(factors2comparewith[0][subjects2use2,:])\n",
    "\n",
    "                                            K = C1.shape[0]\n",
    "                                            R = C1.shape[1]\n",
    "\n",
    "                                            # print(A1.shape,B1[0].shape,C1.shape)\n",
    "\n",
    "                                        else:\n",
    "\n",
    "                                            A1 = deepcopy(factors2compare[2])\n",
    "                                            A2 = deepcopy(factors2comparewith[2])\n",
    "\n",
    "                                            B1 = deepcopy(factors2compare[1])\n",
    "                                            B2 = deepcopy(factors2comparewith[1])\n",
    "\n",
    "                                            C1 = deepcopy(factors2compare[0][subjects2use1,:])\n",
    "                                            C2 = deepcopy(factors2comparewith[0][subjects2use2,:])\n",
    "\n",
    "                                            # print(A1.shape,B1.shape,C1.shape)\n",
    "\n",
    "                                            K = C1.shape[0]\n",
    "                                            R = C1.shape[1]\n",
    "\n",
    "                                            # print(K,R)\n",
    "\n",
    "                                        CB1 = deepcopy(B1)\n",
    "                                        CB2 = deepcopy(B2)\n",
    "\n",
    "                                        if model == 'parafac2':\n",
    "\n",
    "                                            for comp in range(R):\n",
    "                                                for k in range(K):\n",
    "                                                    normm = tl.norm(CB1[k][:,comp])\n",
    "                                                    CB1[k][:,comp] /= normm\n",
    "                                                    normm = tl.norm(CB2[k][:,comp])\n",
    "                                                    CB2[k][:,comp] /= normm\n",
    "\n",
    "                                            for comp in range(R):\n",
    "                                                C1[:,comp] /= tl.norm(C1[:,comp])\n",
    "                                                C2[:,comp] /= tl.norm(C2[:,comp])\n",
    "\n",
    "                                            for comp in range(R):\n",
    "                                                for k in range(K):\n",
    "                                                    CB1[k][:, comp] *= C1[k,comp]\n",
    "                                                    CB2[k][:, comp] *= C2[k,comp]\n",
    "\n",
    "                                        elif model == 'cmf':\n",
    "\n",
    "                                            for comp in range(R):\n",
    "                                                for k in range(K):\n",
    "                                                    normm = tl.norm(CB1[k][:,comp])\n",
    "                                                    CB1[k][:,comp] /= normm\n",
    "                                                    C1[k,comp] *= normm\n",
    "                                                    normm = tl.norm(CB2[k][:,comp])\n",
    "                                                    CB2[k][:,comp] /= normm\n",
    "                                                    C2[k,comp] *= normm\n",
    "\n",
    "                                                normm2 = tl.norm(A1[:,comp])\n",
    "                                                C1[:,comp] *= normm2\n",
    "                                                normm2 = tl.norm(A2[:,comp])\n",
    "                                                C2[:,comp] *= normm2\n",
    "\n",
    "                                            for comp in range(R):\n",
    "                                                C1[:,comp] /= tl.norm(C1[:,comp])\n",
    "                                                C2[:,comp] /= tl.norm(C2[:,comp])\n",
    "\n",
    "                                            for comp in range(R):\n",
    "                                                for k in range(K):\n",
    "                                                    CB1[k][:, comp] *= C1[k, comp]\n",
    "                                                    CB2[k][:, comp] *= C2[k, comp]\n",
    "\n",
    "                                        elif model == 'cp':\n",
    "\n",
    "                                            CB1 = [deepcopy(CB1) for _ in range(K)]\n",
    "                                            CB2 = [deepcopy(CB2) for _ in range(K)]\n",
    "\n",
    "                                            for comp in range(R):\n",
    "                                                for k in range(K):\n",
    "                                                    normm = tl.norm(CB1[k][:,comp])\n",
    "                                                    CB1[k][:,comp] /= normm\n",
    "                                                    normm = tl.norm(CB2[k][:,comp])\n",
    "                                                    CB2[k][:,comp] /= normm\n",
    "\n",
    "                                            for comp in range(R):\n",
    "                                                C1[:,comp] /= tl.norm(C1[:,comp])\n",
    "                                                C2[:,comp] /= tl.norm(C2[:,comp])\n",
    "\n",
    "                                            for comp in range(R):\n",
    "                                                for k in range(K):\n",
    "                                                    CB1[k][:, comp] *= C1[k,comp]\n",
    "                                                    CB2[k][:, comp] *= C2[k,comp]   \n",
    "\n",
    "                                        CB1 = np.vstack(CB1)\n",
    "                                        CB2 = np.vstack(CB2)\n",
    "\n",
    "                                        fmss_A[f'{model}_{no_of_components}_{l_B}_{splits}'].append(congruence_coefficient(A1,A2)[0])\n",
    "                                        fmss_CB[f'{model}_{no_of_components}_{l_B}_{splits}'].append(congruence_coefficient(CB1,CB2)[0])\n",
    "                                        seen_pairs.add(deepcopy(pair_key))\n",
    "\n",
    "                    print(f\"Succesfully loaded {model}_{no_of_components}_{l_B}_{splits}: {len(fmss_A[f'{model}_{no_of_components}_{l_B}_{splits}'])}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f'Error loading {model}_{no_of_components}_{l_B}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8da9386",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m df_cb \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data_cb)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# --- align keys/checks (optional but robust) ---\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m missing_in_cb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(df_cb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     23\u001b[0m missing_in_a  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(df_cb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_in_cb:\n",
      "File \u001b[0;32m~/Documents/PhD/code/Revealing-Subject-specific-Temporal-Patterns-from-Longitudinal-Data/indiv-time-profiles-env/lib/python3.12/site-packages/pandas/core/frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Documents/PhD/code/Revealing-Subject-specific-Temporal-Patterns-from-Longitudinal-Data/indiv-time-profiles-env/lib/python3.12/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "# Prepare data for seaborn\n",
    "data = []\n",
    "for key, values in fmss_A.items():\n",
    "    model, r, l_B,splits = key.split('_')\n",
    "    r = int(r)\n",
    "    l_B = float(l_B)\n",
    "    for v in values:\n",
    "        data.append({'FMS A': v, 'model': model, 'r': r, 'l_B': l_B, 'splits': splits, 'label': key})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# --- build df_CB from ordered_dict_CB in the same way ---\n",
    "data_cb = []\n",
    "for key, values in fmss_CB.items():\n",
    "    model, r, l_B, splits = key.split('_')\n",
    "    r = int(r); l_B = float(l_B)\n",
    "    for v in values:\n",
    "        data_cb.append({'FMS CB': v, 'model': model, 'r': r, 'splits': splits, 'l_B': l_B, 'label': key})\n",
    "df_cb = pd.DataFrame(data_cb)\n",
    "\n",
    "# --- align keys/checks (optional but robust) ---\n",
    "missing_in_cb = sorted(set(df['label']) - set(df_cb['label']))\n",
    "missing_in_a  = sorted(set(df_cb['label']) - set(df['label']))\n",
    "if missing_in_cb:\n",
    "    print(\"Warning: labels missing in CB:\", missing_in_cb)\n",
    "if missing_in_a:\n",
    "    print(\"Warning: labels missing in A:\", missing_in_a)\n",
    "\n",
    "# --- melt to long format with a 'metric' column ---\n",
    "dfa = df.rename(columns={'FMS A': 'value'}).assign(metric='A')[['label','model','r','l_B','metric','value']]\n",
    "dfc = df_cb.rename(columns={'FMS CB': 'value'}).assign(metric='CB')[['label','model','r','l_B','metric','value']]\n",
    "df_long = pd.concat([dfa, dfc], ignore_index=True)\n",
    "\n",
    "# consistent x order (optional: sort by model,r,l_B)\n",
    "order = (df_long[['label','model','r','l_B']]\n",
    "         .drop_duplicates()\n",
    "         .sort_values(['model','r','l_B'])['label']\n",
    "         .tolist())\n",
    "\n",
    "dfa.to_pickle(\"Sensitization/df_A_replic.pkl\")\n",
    "dfc.to_pickle(\"Sensitization/df_CB_replic.pkl\")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.ylim([0.6, 1.005])\n",
    "\n",
    "# Two boxes per label: hue = metric\n",
    "ax = sns.boxplot(\n",
    "    data=df_long, x='label', y='value', hue='metric',\n",
    "    showfliers=True, width=0.6, order=order\n",
    ")\n",
    "\n",
    "# Make the boxes semi-transparent\n",
    "for patch in ax.patches:  # PathPatches\n",
    "    r, g, b, _ = mpl.colors.to_rgba(patch.get_facecolor())\n",
    "    patch.set_facecolor((r, g, b, 0.35))\n",
    "\n",
    "\n",
    "# Single legend (for metric)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# first k handles/labels correspond to 'metric' from the first layer (boxplot)\n",
    "k = df_long['metric'].nunique()  # should be 2\n",
    "ax.legend(handles[:k], labels[:k], title=\"FMS\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "\n",
    "ax.axhline(y=0.9, color='gray', linestyle='--')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Replicability results')\n",
    "plt.ylabel('FMS')\n",
    "plt.ylim([0,1.01])\n",
    "plt.xlabel('Model and Parameters')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indiv-time-profiles-env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
