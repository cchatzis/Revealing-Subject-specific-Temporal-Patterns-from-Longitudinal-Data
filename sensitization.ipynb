{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a41784",
   "metadata": {},
   "source": [
    "# Outline of the sensitization data analysis\n",
    "\n",
    "In this notebook we briefly go through the steps taken to perform the analysis on the sensitization dataset in the paper.\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "We recommend creating a fresh python environment and installing the required libraries via\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fdb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorly.decomposition import non_negative_parafac\n",
    "\n",
    "import matcouply\n",
    "from matcouply.decomposition import cmf_aoadmm, initialize_cmf\n",
    "from matcouply.penalties import Parafac2,NonNegativity\n",
    "\n",
    "from copy import deepcopy\n",
    "import plot_funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e8531",
   "metadata": {},
   "source": [
    "### 1. Load the data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ebdd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# data = sio.loadmat(\"Sensitization/sensitization_data.mat\", simplify_cells=True)[\n",
    "#             \"data\"\n",
    "#         ]\n",
    "\n",
    "# data = tl.transpose(data, (2, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b7d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Scale data (if applicable)\n",
    "\n",
    "def preprocess_centerscale(X, flag_scale=True, flag_center=True):\n",
    "    \"\"\"\n",
    "    Preprocess a 3D array (subjects × time × metabolites):\n",
    "    - Center across subjects (mode-1)\n",
    "    - Scale within each metabolite (mode-3) using RMS\n",
    "    - Handles NaNs\n",
    "\n",
    "    Parameters:\n",
    "    - X: np.ndarray, shape (subjects, time, metabolites)\n",
    "    - flag_scale: bool, whether to apply RMS scaling\n",
    "    - flag_center: bool, whether to apply centering\n",
    "\n",
    "    Returns:\n",
    "    - Xpre: np.ndarray, preprocessed version of X\n",
    "    \"\"\"\n",
    "    Xpre = np.copy(X)\n",
    "\n",
    "    if flag_center:\n",
    "        mean_subjects = np.nanmean(Xpre, axis=0)\n",
    "        for i in range(Xpre.shape[0]):\n",
    "            Xpre[i, :, :] = Xpre[i, :, :] - mean_subjects\n",
    "\n",
    "    if flag_scale:\n",
    "        for k in range(Xpre.shape[2]):\n",
    "            rms = np.sqrt(np.nanmean(Xpre[:, :, k] ** 2))\n",
    "            if rms != 0:\n",
    "                Xpre[:, :, k] /= rms\n",
    "            else:\n",
    "                Xpre[:, :, k] = 0\n",
    "\n",
    "    return Xpre\n",
    "\n",
    "# data = preprocess_centerscale(train, flag_scale=True, flag_center=False)\n",
    "\n",
    "# Normalize data\n",
    "\n",
    "# data = data / tl.norm(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7a4abb",
   "metadata": {},
   "source": [
    "### 2. Reproducibility and replicability analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a904938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check uniqueness\n",
    "\n",
    "# CMF\n",
    "\n",
    "# %run uniqueness_check.py cmf 2 0 -s\n",
    "# %run uniqueness_check.py cmf 3 0 -s\n",
    "# %run uniqueness_check.py cmf 4 0 -s\n",
    "# %run uniqueness_check.py cmf 5 0 -s\n",
    "# %run uniqueness_check.py cmf 6 0 -s\n",
    "\n",
    "# PARAFAC2\n",
    "\n",
    "# %run uniqueness_check.py parafac2 2 0 -s\n",
    "# %run uniqueness_check.py parafac2 3 0 -s\n",
    "# %run uniqueness_check.py parafac2 4 0 -s\n",
    "# %run uniqueness_check.py parafac2 5 0 -s\n",
    "# %run uniqueness_check.py parafac2 6 0 -s\n",
    "\n",
    "# CP\n",
    "\n",
    "# %run uniqueness_check.py cp 2 0 -s\n",
    "# %run uniqueness_check.py cp 3 0 -s\n",
    "# %run uniqueness_check.py cp 4 0 -s\n",
    "# %run uniqueness_check.py cp 5 0 -s\n",
    "# %run uniqueness_check.py cp 6 0 -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beccb504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check replicability\n",
    "\n",
    "# CMF\n",
    "\n",
    "# %run replicability_check.py cmf 2 0 -s\n",
    "# %run replicability_check.py cmf 3 0 -s\n",
    "# %run replicability_check.py cmf 4 0 -s\n",
    "# %run replicability_check.py cmf 5 0 -s\n",
    "# %run replicability_check.py cmf 6 0 -s\n",
    "\n",
    "# PARAFAC2\n",
    "\n",
    "# %run replicability_check.py parafac2 2 0 -s\n",
    "# %run replicability_check.py parafac2 3 0 -s\n",
    "# %run replicability_check.py parafac2 4 0 -s\n",
    "# %run replicability_check.py parafac2 5 0 -s\n",
    "# %run replicability_check.py parafac2 6 0 -s\n",
    "\n",
    "# CP\n",
    "\n",
    "# %run replicability_check.py cp 2 0 -s\n",
    "# %run replicability_check.py cp 3 0 -s\n",
    "# %run replicability_check.py cp 4 0 -s\n",
    "# %run replicability_check.py cp 5 0 -s\n",
    "# %run replicability_check.py cp 6 0 -s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb568696",
   "metadata": {},
   "source": [
    "The output of these scripts is located at `Sensitization/results/uniqueness/` and `Sensitization/results/replicability/`, respectively. The results can be nicely summarized in a plot by `uniqueness_analysis_sensitization.ipynb` and `replicability_analysis_sensitization.ipynb`. To reproduce the exact plot of the paper `paper_plots.ipynb` can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c056e",
   "metadata": {},
   "source": [
    "### 3. Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting CP models\n",
    "\n",
    "best_error = np.inf\n",
    "best_factors = None\n",
    "\n",
    "for init in range(40):\n",
    "\n",
    "    factors, errors = non_negative_parafac(\n",
    "        tensor=data,\n",
    "        tol=1e-8,\n",
    "        rank=6,\n",
    "        return_errors=True,\n",
    "        n_iter_max=15000,\n",
    "        mask=mask,\n",
    "    )\n",
    "\n",
    "    if len(errors) < 14990: # If we have not reached max number of iters\n",
    "        if errors[-1] < best_error: # did we get a better loss?\n",
    "            best_error = errors[-1]\n",
    "            best_factors = factors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5abb0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting PARAFAC2\n",
    "\n",
    "best_error = np.inf\n",
    "best_factors = None\n",
    "\n",
    "for init in range(40):\n",
    "\n",
    "    (weights, (D, B, A)), run_diagnostics = cmf_aoadmm(\n",
    "        matrices=data.T, # This needs to be transposed due to ordering of factors in matcouply\n",
    "        rank=6,\n",
    "        return_errors=True,\n",
    "        n_iter_max=15000,\n",
    "        regs=[\n",
    "            [NonNegativity()],\n",
    "            [NonNegativity(), Parafac2()],\n",
    "            [NonNegativity()],\n",
    "        ],\n",
    "        tol=1e-8,\n",
    "        inner_n_iter_max=20,\n",
    "        absolute_tol=1e-6,\n",
    "        feasibility_tol=1e-5,\n",
    "        inner_tol=1e-5,\n",
    "        mask=mask,\n",
    "    )\n",
    "\n",
    "    if (\n",
    "        len(run_diagnostics.regularized_loss) > 14990\n",
    "    ):\n",
    "        continue\n",
    "    else:\n",
    "        if run_diagnostics.regularized_loss[-1] < best_error:\n",
    "            best_error = run_diagnostics.regularized_loss[-1]\n",
    "            best_factors = (D, B, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3911902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting CMF models\n",
    "\n",
    "best_error = np.inf\n",
    "best_factors = None\n",
    "\n",
    "for init in range(40):\n",
    "\n",
    "    weights, (A_init, B_init, D_init) = initialize_cmf(\n",
    "        matrices=data.T,\n",
    "        rank=6,\n",
    "        init=\"random\",\n",
    "        svd_fun=\"truncated_svd\",\n",
    "    )\n",
    "\n",
    "    A_init = np.ones_like(A_init)\n",
    "    cmf_init = weights, (A_init, B_init, D_init)\n",
    "\n",
    "    (weights, (D, B, A)), run_diagnostics = cmf_aoadmm(\n",
    "        matrices=data.T, # This needs to be transposed due to ordering of factors in matcouply\n",
    "        rank=6,\n",
    "        return_errors=True,\n",
    "        n_iter_max=8000,\n",
    "        regs=[[NonNegativity()], [NonNegativity()], [NonNegativity()]],\n",
    "        tol=1e-8,\n",
    "        init=cmf_init,\n",
    "        update_A=False,\n",
    "        inner_n_iter_max=20,\n",
    "        absolute_tol=1e-6,\n",
    "        feasibility_tol=1e-5,\n",
    "        inner_tol=1e-5,\n",
    "        mask=mask,\n",
    "    )\n",
    "\n",
    "    if (\n",
    "        len(run_diagnostics.regularized_loss) > 7990\n",
    "    ):\n",
    "        continue\n",
    "    else:\n",
    "        if run_diagnostics.regularized_loss[-1] < best_error:\n",
    "            best_error = run_diagnostics.regularized_loss[-1]\n",
    "            best_factors = (D, B, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbcda64",
   "metadata": {},
   "source": [
    "### 4. Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6efd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metadata\n",
    "# df = pd.read_csv('Sensitization/metadata_safe.csv')\n",
    "# meta = df['Delivery(Natural(1)/C-section(2)/Vacuum(3))'].to_numpy()\n",
    "# allergens = ['Mugwort','Birch','Molds','Timothy grass','Wheat flour', 'Milk','Peanut','Egg','Dog','Cat','D.pteronyssinus']\n",
    "# allergens.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47066b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'cmf'\n",
    "n_components = 5\n",
    "\n",
    "if model == 'cp': \n",
    "    A = best_factors[0]\n",
    "    C = best_factors[2]\n",
    "else:\n",
    "    A = best_factors[2]\n",
    "    C = best_factors[0]\n",
    "\n",
    "if model != 'cp':\n",
    "    B = best_factors[1]\n",
    "else:\n",
    "    B = [deepcopy(best_factors[1]) for _ in range(C.shape[0])]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    5, 4,\n",
    "    figsize=(8,0.65 * 8),\n",
    "    constrained_layout=False\n",
    ")\n",
    "\n",
    "fig.subplots_adjust(\n",
    "    left=0.06, right=0.875, bottom=0.08, top=0.97,\n",
    "    wspace=0.24, hspace=0.175\n",
    ")\n",
    "\n",
    "for i, comp in enumerate([3,0,2,1,4]): # same order as in the paper\n",
    "    if i == 0: \n",
    "        plot_funcs.plot_allergens_component(factors=(A,B,C),comp=comp, allergens=allergens, axes=axs[i,0],plot_title=True,comp_i=i)\n",
    "        plot_funcs.plot_sensitization_profiles_component(factors=(A,B,C),comp=comp,axes=axs[i,1],comp_i=i,plot_title=True,time_points=[ 0.5,  1.5,  4. ,  6. , 13. , 18. ])\n",
    "        plot_funcs.plot_sensitization_mean_profile_component(factors=(A,B,C),comp=comp,axes=axs[i,2],plot_title=True,time_points=[ 0.5,  1.5,  4. ,  6. , 13. , 18. ])\n",
    "        plot_funcs.plot_sensitization_profiles_stratified_component(factors=(A,B,C),comp=comp,axes=axs[i,3],meta=meta,plot_title=True,time_points=[ 0.5,  1.5,  4. ,  6. , 13. , 18. ])\n",
    "    elif i == 4: \n",
    "        plot_funcs.plot_allergens_component(factors=(A,B,C),comp=comp,allergens=allergens,axes=axs[i,0],plot_xticks=True,plot_legend=True,comp_i=i)\n",
    "        plot_funcs.plot_sensitization_profiles_component(factors=(A,B,C),comp=comp,axes=axs[i,1],comp_i=i,plot_legend=True,plot_xticks=True,time_points=[ 0.5,  1.5,  4. ,  6. , 13. , 18. ])\n",
    "        plot_funcs.plot_sensitization_mean_profile_component(factors=(A,B,C),comp=comp,axes=axs[i,2],plot_legend=True,plot_xticks=True,time_points=[ 0.5,  1.5,  4. ,  6. , 13. , 18. ])\n",
    "        plot_funcs.plot_sensitization_profiles_stratified_component(factors=(A,B,C),meta=meta,comp=comp,axes=axs[i,3],plot_legend=True,plot_xticks=True,time_points=[ 0.5,  1.5,  4. ,  6. , 13. , 18. ])\n",
    "    else: \n",
    "        plot_funcs.plot_allergens_component(factors=(A,B,C),comp=comp,allergens=allergens,axes=axs[i,0],comp_i=i)\n",
    "        plot_funcs.plot_sensitization_profiles_component(factors=(A,B,C),comp=comp,axes=axs[i,1],comp_i=i,time_points=[ 0.5,  1.5,  4. ,  6. , 13. , 18. ])\n",
    "        plot_funcs.plot_sensitization_mean_profile_component(factors=(A,B,C),comp=comp,axes=axs[i,2],plot_legend=True,plot_xticks=True,time_points=[ 0.5,  1.5,  4. ,  6. , 13. , 18. ])\n",
    "        plot_funcs.plot_sensitization_profiles_stratified_component(factors=(A,B,C),meta=meta,comp=comp,axes=axs[i,3],time_points=[ 0.5,  1.5,  4. ,  6. , 13. , 18. ])\n",
    "\n",
    "for ax in fig.axes:\n",
    "    # Tick labels\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", labelsize=5)\n",
    "\n",
    "    # Axes title + axis labels\n",
    "    ax.title.set_fontsize(6)\n",
    "    ax.xaxis.label.set_fontsize(5)\n",
    "    ax.yaxis.label.set_fontsize(5)\n",
    "\n",
    "    leg = ax.get_legend()\n",
    "    if leg is not None:\n",
    "        for t in leg.get_texts():\n",
    "            t.set_fontsize(5)\n",
    "        if leg.get_title() is not None:\n",
    "            leg.get_title().set_fontsize(5)\n",
    "\n",
    "\n",
    "axs[0,2].set_xticklabels([])\n",
    "axs[1,2].set_xticklabels([])\n",
    "axs[2,2].set_xticklabels([])\n",
    "axs[3,2].set_xticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
